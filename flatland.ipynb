{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcLvwuwR_GYF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import datetime\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "data = np.load('flatland_train.npz')\n",
        "X = data['X']\n",
        "y = data['y']\n"
      ],
      "metadata": {
        "id": "8BXeDIE8_WiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "X = X / 255.0\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "y = to_categorical(y)\n"
      ],
      "metadata": {
        "id": "riB_PW9O_elZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pixel values of the images are normalized to the range [0, 1] by dividing by 255.0. The labels (y) are encoded using LabelEncoder and then converted to one-hot encoded format using to_categorical."
      ],
      "metadata": {
        "id": "8C8m_pyaWQz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "jqIkDWu0_j7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is split into training and testing sets using the train_test_split function from scikit-learn. 80% of the data is used for training (X_train, y_train), and 20% is used for testing (X_test, y_test)."
      ],
      "metadata": {
        "id": "TMrYnXweWfdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the input data has the correct shape (add channel dimension for grayscale images)\n",
        "X_train = X_train.reshape(X_train.shape + (1,))\n",
        "X_test = X_test.reshape(X_test.shape + (1,))"
      ],
      "metadata": {
        "id": "RnIegFquAMUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n"
      ],
      "metadata": {
        "id": "_r4YAUm7_pg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ImageDataGenerator is configured with various transformations like rotation, width shift, height shift, shear, zoom, horizontal flip, and vertical flip. This generator will be used to augment the training data during model training."
      ],
      "metadata": {
        "id": "zx3UjphXWpPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=X_train.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
        "\n"
      ],
      "metadata": {
        "id": "pI2Q5ptM_vzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is built using the Sequential API from Keras. It consists of convolutional layers (Conv2D), batch normalization layers (BatchNormalization), max-pooling layers (MaxPooling2D), a flattening layer (Flatten), dense layers (Dense), and a dropout layer (Dropout). The final layer has softmax activation, suitable for multiclass classification."
      ],
      "metadata": {
        "id": "djZ9FlHRWu49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "LEz9tlZRAYqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is compiled with the Adam optimizer, categorical crossentropy loss (suitable for multiclass classification), and accuracy as the evaluation metric."
      ],
      "metadata": {
        "id": "yg2o7XQtWx_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model callbacks\n",
        "checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "metadata": {
        "id": "Yl5FfEgQAstJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with data augmentation\n",
        "history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
        "                    steps_per_epoch=len(X_train) / 32,\n",
        "                    epochs=50,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=[checkpoint, early_stopping, tensorboard])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EYeZVmhAvbM",
        "outputId": "b91761f8-5eed-433e-f5a2-8876d433f11a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 1.7681 - accuracy: 0.3666\n",
            "Epoch 1: val_loss improved from inf to 1.97891, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r250/250 [==============================] - 42s 161ms/step - loss: 1.7681 - accuracy: 0.3666 - val_loss: 1.9789 - val_accuracy: 0.2195\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 1.3619 - accuracy: 0.4518\n",
            "Epoch 2: val_loss improved from 1.97891 to 1.64817, saving model to best_model.h5\n",
            "250/250 [==============================] - 39s 156ms/step - loss: 1.3619 - accuracy: 0.4518 - val_loss: 1.6482 - val_accuracy: 0.1850\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.9887 - accuracy: 0.5824\n",
            "Epoch 3: val_loss improved from 1.64817 to 0.66472, saving model to best_model.h5\n",
            "250/250 [==============================] - 40s 160ms/step - loss: 0.9887 - accuracy: 0.5824 - val_loss: 0.6647 - val_accuracy: 0.7585\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.7470 - accuracy: 0.7091\n",
            "Epoch 4: val_loss did not improve from 0.66472\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.7470 - accuracy: 0.7091 - val_loss: 0.7090 - val_accuracy: 0.6480\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.5997 - accuracy: 0.7872\n",
            "Epoch 5: val_loss improved from 0.66472 to 0.43382, saving model to best_model.h5\n",
            "250/250 [==============================] - 40s 161ms/step - loss: 0.5997 - accuracy: 0.7872 - val_loss: 0.4338 - val_accuracy: 0.8585\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.5128 - accuracy: 0.8284\n",
            "Epoch 6: val_loss did not improve from 0.43382\n",
            "250/250 [==============================] - 40s 160ms/step - loss: 0.5128 - accuracy: 0.8284 - val_loss: 0.6431 - val_accuracy: 0.7480\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.4528 - accuracy: 0.8569\n",
            "Epoch 7: val_loss improved from 0.43382 to 0.35895, saving model to best_model.h5\n",
            "250/250 [==============================] - 39s 154ms/step - loss: 0.4528 - accuracy: 0.8569 - val_loss: 0.3589 - val_accuracy: 0.9085\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.4310 - accuracy: 0.8683\n",
            "Epoch 8: val_loss improved from 0.35895 to 0.30226, saving model to best_model.h5\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.4310 - accuracy: 0.8683 - val_loss: 0.3023 - val_accuracy: 0.9285\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.3905 - accuracy: 0.8882\n",
            "Epoch 9: val_loss did not improve from 0.30226\n",
            "250/250 [==============================] - 39s 158ms/step - loss: 0.3905 - accuracy: 0.8882 - val_loss: 0.3193 - val_accuracy: 0.9110\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.3664 - accuracy: 0.8994\n",
            "Epoch 10: val_loss did not improve from 0.30226\n",
            "250/250 [==============================] - 42s 166ms/step - loss: 0.3664 - accuracy: 0.8994 - val_loss: 3.4579 - val_accuracy: 0.4720\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.3508 - accuracy: 0.9000\n",
            "Epoch 11: val_loss did not improve from 0.30226\n",
            "250/250 [==============================] - 39s 154ms/step - loss: 0.3508 - accuracy: 0.9000 - val_loss: 0.3862 - val_accuracy: 0.8955\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.3341 - accuracy: 0.9091\n",
            "Epoch 12: val_loss did not improve from 0.30226\n",
            "250/250 [==============================] - 41s 162ms/step - loss: 0.3341 - accuracy: 0.9091 - val_loss: 0.3499 - val_accuracy: 0.9085\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.3125 - accuracy: 0.9133\n",
            "Epoch 13: val_loss improved from 0.30226 to 0.23317, saving model to best_model.h5\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.3125 - accuracy: 0.9133 - val_loss: 0.2332 - val_accuracy: 0.9600\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2931 - accuracy: 0.9259\n",
            "Epoch 14: val_loss did not improve from 0.23317\n",
            "250/250 [==============================] - 39s 157ms/step - loss: 0.2931 - accuracy: 0.9259 - val_loss: 0.3000 - val_accuracy: 0.9230\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2996 - accuracy: 0.9258\n",
            "Epoch 15: val_loss did not improve from 0.23317\n",
            "250/250 [==============================] - 40s 160ms/step - loss: 0.2996 - accuracy: 0.9258 - val_loss: 0.5465 - val_accuracy: 0.8100\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2910 - accuracy: 0.9231\n",
            "Epoch 16: val_loss did not improve from 0.23317\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.2910 - accuracy: 0.9231 - val_loss: 0.5668 - val_accuracy: 0.8170\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2746 - accuracy: 0.9339\n",
            "Epoch 17: val_loss improved from 0.23317 to 0.22487, saving model to best_model.h5\n",
            "250/250 [==============================] - 38s 151ms/step - loss: 0.2746 - accuracy: 0.9339 - val_loss: 0.2249 - val_accuracy: 0.9590\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2544 - accuracy: 0.9398\n",
            "Epoch 18: val_loss improved from 0.22487 to 0.18041, saving model to best_model.h5\n",
            "250/250 [==============================] - 41s 163ms/step - loss: 0.2544 - accuracy: 0.9398 - val_loss: 0.1804 - val_accuracy: 0.9805\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2594 - accuracy: 0.9401\n",
            "Epoch 19: val_loss did not improve from 0.18041\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.2594 - accuracy: 0.9401 - val_loss: 0.3258 - val_accuracy: 0.9215\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2397 - accuracy: 0.9445\n",
            "Epoch 20: val_loss did not improve from 0.18041\n",
            "250/250 [==============================] - 39s 157ms/step - loss: 0.2397 - accuracy: 0.9445 - val_loss: 0.2374 - val_accuracy: 0.9500\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2559 - accuracy: 0.9415\n",
            "Epoch 21: val_loss did not improve from 0.18041\n",
            "250/250 [==============================] - 40s 160ms/step - loss: 0.2559 - accuracy: 0.9415 - val_loss: 0.3592 - val_accuracy: 0.9000\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2379 - accuracy: 0.9459\n",
            "Epoch 22: val_loss improved from 0.18041 to 0.16954, saving model to best_model.h5\n",
            "250/250 [==============================] - 38s 150ms/step - loss: 0.2379 - accuracy: 0.9459 - val_loss: 0.1695 - val_accuracy: 0.9795\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.9479\n",
            "Epoch 23: val_loss did not improve from 0.16954\n",
            "250/250 [==============================] - 40s 162ms/step - loss: 0.2363 - accuracy: 0.9479 - val_loss: 0.3428 - val_accuracy: 0.9145\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2413 - accuracy: 0.9451\n",
            "Epoch 24: val_loss did not improve from 0.16954\n",
            "250/250 [==============================] - 40s 159ms/step - loss: 0.2413 - accuracy: 0.9451 - val_loss: 1.0169 - val_accuracy: 0.6785\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2249 - accuracy: 0.9516\n",
            "Epoch 25: val_loss did not improve from 0.16954\n",
            "250/250 [==============================] - 40s 160ms/step - loss: 0.2249 - accuracy: 0.9516 - val_loss: 0.1900 - val_accuracy: 0.9675\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2263 - accuracy: 0.9503\n",
            "Epoch 26: val_loss did not improve from 0.16954\n",
            "250/250 [==============================] - 38s 150ms/step - loss: 0.2263 - accuracy: 0.9503 - val_loss: 0.2782 - val_accuracy: 0.9370\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2364 - accuracy: 0.9484\n",
            "Epoch 27: val_loss did not improve from 0.16954\n",
            "250/250 [==============================] - 40s 158ms/step - loss: 0.2364 - accuracy: 0.9484 - val_loss: 0.4540 - val_accuracy: 0.8675\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.9511\n",
            "Epoch 28: val_loss improved from 0.16954 to 0.15184, saving model to best_model.h5\n",
            "250/250 [==============================] - 40s 159ms/step - loss: 0.2232 - accuracy: 0.9511 - val_loss: 0.1518 - val_accuracy: 0.9820\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2143 - accuracy: 0.9520\n",
            "Epoch 29: val_loss did not improve from 0.15184\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.2143 - accuracy: 0.9520 - val_loss: 0.3984 - val_accuracy: 0.8960\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2119 - accuracy: 0.9574\n",
            "Epoch 30: val_loss did not improve from 0.15184\n",
            "250/250 [==============================] - 40s 158ms/step - loss: 0.2119 - accuracy: 0.9574 - val_loss: 0.1651 - val_accuracy: 0.9700\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2181 - accuracy: 0.9529\n",
            "Epoch 31: val_loss did not improve from 0.15184\n",
            "250/250 [==============================] - 42s 167ms/step - loss: 0.2181 - accuracy: 0.9529 - val_loss: 0.2091 - val_accuracy: 0.9720\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2193 - accuracy: 0.9556\n",
            "Epoch 32: val_loss did not improve from 0.15184\n",
            "250/250 [==============================] - 38s 151ms/step - loss: 0.2193 - accuracy: 0.9556 - val_loss: 0.3404 - val_accuracy: 0.8980\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.9532\n",
            "Epoch 33: val_loss did not improve from 0.15184\n",
            "250/250 [==============================] - 41s 163ms/step - loss: 0.2238 - accuracy: 0.9532 - val_loss: 0.2629 - val_accuracy: 0.9365\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.9539\n",
            "Epoch 34: val_loss did not improve from 0.15184\n",
            "250/250 [==============================] - 39s 157ms/step - loss: 0.2177 - accuracy: 0.9539 - val_loss: 0.1913 - val_accuracy: 0.9745\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.2128 - accuracy: 0.9557\n",
            "Epoch 35: val_loss did not improve from 0.15184\n",
            "250/250 [==============================] - 42s 168ms/step - loss: 0.2128 - accuracy: 0.9557 - val_loss: 0.1626 - val_accuracy: 0.9830\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.1904 - accuracy: 0.9634\n",
            "Epoch 36: val_loss did not improve from 0.15184\n",
            "250/250 [==============================] - 40s 158ms/step - loss: 0.1904 - accuracy: 0.9634 - val_loss: 0.1545 - val_accuracy: 0.9850\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.1854 - accuracy: 0.9670\n",
            "Epoch 37: val_loss did not improve from 0.15184\n",
            "250/250 [==============================] - 38s 154ms/step - loss: 0.1854 - accuracy: 0.9670 - val_loss: 0.2678 - val_accuracy: 0.9330\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.1983 - accuracy: 0.9603\n",
            "Epoch 38: val_loss did not improve from 0.15184\n",
            "250/250 [==============================] - 41s 162ms/step - loss: 0.1983 - accuracy: 0.9603 - val_loss: 0.1955 - val_accuracy: 0.9715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is trained using the fit method. The training data is augmented using the datagen.flow generator. The training process is monitored by callbacks, including model checkpointing (ModelCheckpoint), early stopping (EarlyStopping), and TensorBoard logging (TensorBoard)."
      ],
      "metadata": {
        "id": "qi4p4P6GW4AP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmSsem_SHs3U",
        "outputId": "9e38931a-5468-4959-cb32-81342f9bbb80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 2s 29ms/step - loss: 0.1518 - accuracy: 0.9820\n",
            "Test Accuracy: 0.9819999933242798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trained model is evaluated on the test set using the evaluate method. The test accuracy is then printed."
      ],
      "metadata": {
        "id": "JGgpID0TW6tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final model\n",
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "hN-g9TReH3VH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}